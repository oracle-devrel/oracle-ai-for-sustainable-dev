{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd60c3c",
   "metadata": {},
   "source": [
    "# Pinpoint suspicious financial transactions with Oracle Spatial and Python\n",
    "\n",
    "In this workshop you will identify suspicious financial transactions based on analysis involving location and time (\"spatiotemporal\"). Both the spatial features of Oracle Database (i.e., \"Oracle Spatial\") and Python libraries are used. Oracle Spatial performs back-end large scale location analysis and enrichment based on relationships and measurements such as proximity, containment, distance and area. Python provides an environment for data analysis and machine learning leveraging a vast ecosystem of mature specialized libraries, including spatiotemporal analysis. The python-oracledb driver enables connectivity and robust access to Oracle Database, so that the strengths of both the Oracle back-end and Python client are optimally leveraged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deaec8a-fa94-4232-a59d-8e3c4b9b20e7",
   "metadata": {},
   "source": [
    "## Connect to Autonomous Database from Python\n",
    "To prepare for data loading and analysis, you first establish a connection from Python to your Autonomous Database. The python-oracledb driver supports this connection and all subsequent database interactions. You will use the python-oracledb driver's ‘Thin’ mode which connects directly to Oracle Database and does not need Oracle Client libraries.\n",
    "\n",
    "### Load the python-oracedb module\n",
    "In the first cell, run the following statement. This loads the python-oracedb module which handles interaction with Oracle Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b97808-a123-480c-84fe-fc33572a78c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import oracledb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40444b1-de15-4d10-8fbf-f1ab01f128e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load your ADB password and DSN into variables\n",
    "Run the following statements. This loads your ADB password and DSN into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185c2fb-71e9-4b1f-b9df-4e2fafa5a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TNS_ADMIN\"] = \"/Users/pparkins/Downloads/Wallet_financialdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6b755-3065-42aa-858a-490a9d193c94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get ADB password and DSN from file\n",
    "my_pwd = open('./my-pwd.txt','r').readline().strip()\n",
    "my_dsn = open('./my-dsn.txt','r').readline().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5082c8-73c7-48b7-9770-ba7bed87d28e",
   "metadata": {},
   "source": [
    "### Create a connection to your ADB\n",
    "Run the following statements. This creates a connection to your ADB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc64162-aaa8-4abe-b684-501b1137c2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "DPY-6005: cannot connect to database (CONNECTION_ID=AgvYCIkoS87PAeXh0Q/xPw==).\nDPY-4011: the database or network closed the connection\n[Errno 54] Connection reset by peer\nHelp: https://python-oracledb.readthedocs.io/en/latest/user_guide/troubleshooting.html#dpy-4011",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32msrc/oracledb/impl/thin/transport.pyx:323\u001b[0m, in \u001b[0;36moracledb.thin_impl.Transport.read_packet\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 54] Connection reset by peer",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32msrc/oracledb/impl/thin/connection.pyx:279\u001b[0m, in \u001b[0;36moracledb.thin_impl.ThinConnImpl._connect_with_address\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/protocol.pyx:242\u001b[0m, in \u001b[0;36moracledb.thin_impl.Protocol._connect_phase_one\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/protocol.pyx:400\u001b[0m, in \u001b[0;36moracledb.thin_impl.Protocol._process_message\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/protocol.pyx:378\u001b[0m, in \u001b[0;36moracledb.thin_impl.Protocol._process_message\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/protocol.pyx:452\u001b[0m, in \u001b[0;36moracledb.thin_impl.Protocol._receive_packet\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/packet.pyx:698\u001b[0m, in \u001b[0;36moracledb.thin_impl.ReadBuffer.wait_for_packets_sync\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/transport.pyx:325\u001b[0m, in \u001b[0;36moracledb.thin_impl.Transport.read_packet\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/oracledb/errors.py:182\u001b[0m, in \u001b[0;36m_raise_err\u001b[0;34m(error_num, context_error_message, cause, **args)\u001b[0m\n\u001b[1;32m    181\u001b[0m error \u001b[38;5;241m=\u001b[39m _Error(message)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mexc_type(error) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcause\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: DPY-4011: the database or network closed the connection\n[Errno 54] Connection reset by peer\nHelp: https://python-oracledb.readthedocs.io/en/latest/user_guide/troubleshooting.html#dpy-4011",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create database connection and cursor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[43moracledb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinancial\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWelcome12345\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madb.eu-frankfurt-1.oraclecloud.com:1522/ij1tyzir3wpwlpe_financialdb_high.adb.oraclecloud.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m cursor \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcursor()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/oracledb/connection.py:1158\u001b[0m, in \u001b[0;36m_connection_factory.<locals>.connect\u001b[0;34m(dsn, pool, conn_class, params, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpool must be an instance of oracledb.ConnectionPool\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconn_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/oracledb/connection.py:541\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, dsn, pool, params, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m         impl \u001b[38;5;241m=\u001b[39m thin_impl\u001b[38;5;241m.\u001b[39mThinConnImpl(dsn, params_impl)\n\u001b[0;32m--> 541\u001b[0m         \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_impl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    543\u001b[0m     impl \u001b[38;5;241m=\u001b[39m thick_impl\u001b[38;5;241m.\u001b[39mThickConnImpl(dsn, params_impl)\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/connection.pyx:381\u001b[0m, in \u001b[0;36moracledb.thin_impl.ThinConnImpl.connect\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/connection.pyx:377\u001b[0m, in \u001b[0;36moracledb.thin_impl.ThinConnImpl.connect\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/connection.pyx:337\u001b[0m, in \u001b[0;36moracledb.thin_impl.ThinConnImpl._connect_with_params\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/connection.pyx:318\u001b[0m, in \u001b[0;36moracledb.thin_impl.ThinConnImpl._connect_with_description\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/oracledb/impl/thin/connection.pyx:284\u001b[0m, in \u001b[0;36moracledb.thin_impl.ThinConnImpl._connect_with_address\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/oracledb/errors.py:182\u001b[0m, in \u001b[0;36m_raise_err\u001b[0;34m(error_num, context_error_message, cause, **args)\u001b[0m\n\u001b[1;32m    180\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcontext_error_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m error \u001b[38;5;241m=\u001b[39m _Error(message)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mexc_type(error) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcause\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: DPY-6005: cannot connect to database (CONNECTION_ID=AgvYCIkoS87PAeXh0Q/xPw==).\nDPY-4011: the database or network closed the connection\n[Errno 54] Connection reset by peer\nHelp: https://python-oracledb.readthedocs.io/en/latest/user_guide/troubleshooting.html#dpy-4011"
     ]
    }
   ],
   "source": [
    "# Create database connection and cursor\n",
    "connection = oracledb.connect(user=\"financial\", password=\"Welcome12345\", dsn=\"adb.eu-frankfurt-1.oraclecloud.com:1522/ij1tyzir3wpwlpe_financialdb_high.adb.oraclecloud.com\")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac592c-a507-4893-9a1e-67057f3a8e55",
   "metadata": {},
   "source": [
    "### Test connection to your ADB\n",
    "Run the following statements. This runs a test query to verify successful connection to ADB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199203a9-abc7-492c-9fe8-9e7ee284d27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run a test query\n",
    "cursor.execute(\"select object_type, count(*) from all_objects group by object_type\")\n",
    "for row in cursor.fetchmany(size=10):\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c533f5-660f-44c4-b5e3-22bf6d587dd3",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "Load fictitious financial transactions data to your Autonomous Database and configure for spatial and temporal (\"spatiotemporal\") analysis.\n",
    "### Create and Load Tables\n",
    "Run the following cells to create `locations` and `transactions` tables, and load them with data from the `locations.csv` and `transactions.csv` files. Then, query the tables to ensure that data was loaded successfully, and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07f3e2-fc50-4a4e-9350-893997de2550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create table for locations data\n",
    "cursor.execute(\"\"\"\n",
    " CREATE TABLE locations (\n",
    "           location_id INTEGER, \n",
    "           owner VARCHAR2(100),  \n",
    "           lon NUMBER, \n",
    "           lat NUMBER)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec36bd3-fd35-4ded-9ae9-1eff50b6209f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the locations data\n",
    "import csv\n",
    "BATCH_SIZE = 1000\n",
    "with connection.cursor() as cursor:\n",
    "    with open('locations.csv', 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        #skip header\n",
    "        next(csv_reader) \n",
    "        #load data\n",
    "        sql = \"INSERT INTO locations VALUES (:1, :2, :3, :4)\"\n",
    "        data = []\n",
    "        for line in csv_reader:\n",
    "            data.append((line[0], line[1], line[2], line[3]))\n",
    "            if len(data) % BATCH_SIZE == 0:\n",
    "                cursor.executemany(sql, data)\n",
    "                data = []\n",
    "        if data:\n",
    "            cursor.executemany(sql, data)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd68304-3db6-449b-aec9-db23cbf5a26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preview locations data\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM locations\")\n",
    "for row in cursor.fetchmany(size=10):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275c3bf-4022-465f-884d-982c9f2c5d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create table for transactions data\n",
    "cursor.execute(\"\"\"\n",
    "   CREATE TABLE transactions (\n",
    "                  trans_id INTEGER,\n",
    "                  location_id INTEGER, \n",
    "                  trans_date DATE, \n",
    "                  cust_id INTEGER)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac10b4-ddb6-4d0f-a929-071caf137c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the transactions data\n",
    "BATCH_SIZE = 1000\n",
    "with connection.cursor() as cursor:\n",
    "    with open('transactions.csv', 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        #skip header\n",
    "        next(csv_reader) \n",
    "        #load data\n",
    "        sql = \"INSERT INTO transactions VALUES (:1, :2, TO_DATE(:3,'YYYY-MM-DD:HH24:MI:SS'), :4)\"\n",
    "        data = []\n",
    "        for line in csv_reader:\n",
    "            data.append((line[0], line[1], line[2], line[3]))\n",
    "            if len(data) % BATCH_SIZE == 0:\n",
    "                cursor.executemany(sql, data)\n",
    "                data = []\n",
    "        if data:\n",
    "            cursor.executemany(sql, data)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128eb22b-cd9f-4a4d-8802-d51721e6fd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preview transactions data\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM transactions\")\n",
    "for row in cursor.fetchmany(size=10):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd56136-4d50-49bc-8d5e-9c0652c273d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get distinct Customer ID's\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT DISTINCT cust_id FROM transactions ORDER BY cust_id\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e24f4-f85a-456c-ad02-d4f6402fe969",
   "metadata": {},
   "source": [
    "### Add Epoch Date\n",
    "Temporal calculations are a key component of this workshop, and are best performed on an integer representation of date and time. This integer representation is generally referred to as epoch time or more specifically UNIX time. In this task you add epoch time for all transactions.\n",
    "\n",
    "#### Add and populate epoch date column\n",
    "Run the following cells to add and populate a column for epoch date. Then, preview the transaction data, and observe the epoch date column is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97df5f-3812-4b8c-b6fc-9955d3397f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add column for epoch date\n",
    "cursor.execute(\"ALTER TABLE transactions ADD (trans_epoch_date integer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa22ecf-fe29-474b-94cc-15612d410e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# populate epoch date\n",
    "cursor.execute(\"\"\"UPDATE transactions \n",
    "                  SET trans_epoch_date = (trans_date - date'1970-01-01') * 86400\"\"\")\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4722fe-458c-4506-a104-b37590bbdb03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preview transactions data\n",
    "cursor.execute(\"SELECT * FROM transactions\")\n",
    "for row in cursor.fetchmany(size=10):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf312d6-cd74-4523-94d9-cffa97e50177",
   "metadata": {},
   "source": [
    "### Configure data for Spatial Operations\n",
    "Spatial calculations are an additional key component of this workshop. In this task you configure your locations data to utilize the spatial features of Autonomous Database. The locations table includes longitude/latitude coordinates. One option is to create and populate a new column using the native spatial data type. While that would work perfectly fine, there is another option that takes advantage of a mainstream Oracle Database feature called \"function-based indexing\". This approach allows for all of the capability associated with creating a new spatial column, but without having to create the column. Instead, you create a database function that converts coordinates to a spatial data element, and then create an index on that function. Once the function and index are created, all spatial operations behave as if a new spatial column had been created. While this is not essential for the small data volume in this workshop, the approach is of great benefit for large scale systems where the overhead of adding a column is significant.\n",
    "\n",
    "#### Create SQL function lonlat_to_proj_geom( ) \n",
    "Run the following cells to to create and test a function that converts longitude/latitude coordinates to Oracle's native spatial data type (i.e. SDO_GEOMETRY, referred to as a \"geometry\"). Not only does the function convert coordinates to the native spatial type, but it also converts the coordinates from longitude/latitude to a projected coordinate system with x/y coordinates in meters. This coordiate system coversion is required by Python libraries used in subsequent labs, hence it is convenient to perform this conversion in this function.\n",
    "\n",
    "Run the following cells to create and test the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c5f40-6fa5-466c-8c14-2e186703ae46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create function to return lon/lat coordinates as a geometry.\n",
    "cursor.execute(\"\"\"\n",
    " CREATE OR REPLACE FUNCTION lonlat_to_proj_geom (longitude IN NUMBER, latitude IN NUMBER)\n",
    " RETURN SDO_GEOMETRY DETERMINISTIC IS\n",
    " BEGIN\n",
    "   IF latitude IS NULL OR longitude IS NULL\n",
    "   OR latitude NOT BETWEEN -90 AND 90\n",
    "   OR longitude NOT BETWEEN -180 AND 180\n",
    "   THEN\n",
    "     RETURN NULL;\n",
    "   ELSE\n",
    "      RETURN sdo_cs.transform(\n",
    "        SDO_GEOMETRY(2001, 4326,\n",
    "                     sdo_point_type(longitude, latitude, NULL),NULL, NULL),\n",
    "        3857);\n",
    "   END IF;\n",
    "END;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac672e4-b2c7-450c-bf86-e5151698f4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return LOBs directly as strings or bytes\n",
    "oracledb.defaults.fetch_lobs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1336ec-2b11-41fc-b3d5-625ad4116825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test the function\n",
    "cursor.execute(\"\"\"\n",
    " with x as (\n",
    "    SELECT location_id, lonlat_to_proj_geom(lon,lat) as geom FROM locations)\n",
    " SELECT location_id, geom, (geom).get_wkt()\n",
    " FROM x\n",
    " \"\"\")\n",
    "for row in cursor.fetchone():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0de387-2e05-42ad-a4d9-7970603b96f9",
   "metadata": {},
   "source": [
    "### Create Spatial Index\n",
    "Spatial queries rely on a spatial index for optimal performance. A spatial index can only be created on data having uniform dimensionality (i.e., 2D or 3D) and coordinate system. Before creating a spatial index, it is necessary to insert a row of metadata describing these properties for the geometry to be indexed. This includes the table name, geometry column name (or in this case a function returning geometry), dimensionality , and a coordinate system code. When creating a spatial index, the data are first verified to conform to the metadata. Spatial indexing completes successfully only if the data conform to the metadata. \n",
    "\n",
    "Run the following cells to insert a row of metadata, create a spatial index, and run a spatial query to verify the spatial index.The spatial query returns the 5 nearest items from the locations table to a longitude/latitude coordinate, along with the distances. This is referred to as a \"nearest neighbor\" query and uses the sdo_nn( ) operator which uses the spatial index. For more info on nearest neighbor queries, please see the [documentation](https://docs.oracle.com/en/database/oracle/oracle-database/19/spatl/spatial-operators-reference.html#GUID-41E6B1FA-1A03-480B-996F-830E8566661D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a72dd-f66f-4813-abaf-64a4e25259a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insert spatial metadata\n",
    "cursor.execute(\"\"\"\n",
    " INSERT INTO user_sdo_geom_metadata VALUES (\n",
    "    'LOCATIONS', 'ADMIN.LONLAT_TO_PROJ_GEOM(LON,LAT)',\n",
    "     SDO_DIM_ARRAY(SDO_DIM_ELEMENT('LON', 0, 0, 0.05),\n",
    "                   SDO_DIM_ELEMENT('LAT', 0, 0, 0.05)),\n",
    "     3857)\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11961727-ae42-4b8e-abda-19f0c097648b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create spatial index\n",
    "cursor.execute(\"\"\"\n",
    " CREATE INDEX locations_sidx\n",
    " ON locations(LONLAT_TO_PROJ_GEOM(LON,LAT))\n",
    " INDEXTYPE IS mdsys.spatial_index_v2\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee8f00-b09f-49cd-a654-95011439864c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run test query that uses spatial index\n",
    "cursor.execute(\"\"\"\n",
    " SELECT location_id, round(sdo_nn_distance(1), 2) FROM locations\n",
    " WHERE sdo_nn(\n",
    "   LONLAT_TO_PROJ_GEOM(LON,LAT),\n",
    "   LONLAT_TO_PROJ_GEOM( -97.6, 30.3),\n",
    "   'sdo_num_res=5 unit=mile', 1) = 'TRUE' \"\"\")\n",
    "for row in cursor.fetchmany():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536db7f-d9e0-4cae-8e5c-604ce55bace6",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "Explore the locations and transactions data prepared in the previous steps. By managing the data in Autonomous Database, you are able to perform back-end processing and analysis operations and then bring appropriate data subsets into Python for specialized analyses.\n",
    "\n",
    "### Spatial data handling in Python\n",
    "The most common Python library for data handling is Pandas, which provides DataFrame as the data structure akin to a table with columns and rows. The GeoPandas library extends Pandas for spatial data handling, where DataFrame is extended to GeoDataFrame including a \"geometry\" column. The Shapely library provides the spatial type used to populate the geometry column. Folium is a popular map visualization library and is used by GeoPandas.\n",
    "\n",
    "In the following cells, import the libraries for spatial data handling and map visualization, and run throug ha simple example of spatial data in Python. These cells will create a GeoDataFrame containing point locations for several cities. The geometry values are in Well-Known Text (\"WKT\") format since that is the format used in a GeoDataFrame. Then, visualize the data by specifying both the background map and marker size. Move your mouse over a map marker to see its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c890030-942a-4142-9fd6-25be3e209bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956482e-1152-4bed-be4e-1daafdf22689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "  {\n",
    "    \"city\": [\"Buenos Aires\", \"Brasilia\", \"Santiago\", \"Bogota\", \"Caracas\"],\n",
    "    \"country\": [\"Argentina\", \"Brazil\", \"Chile\", \"Colombia\", \"Venezuela\"],\n",
    "    \"geometry\": [\"POINT(-58.66 -34.58)\",\n",
    "                 \"POINT(-47.91 -15.78)\",\n",
    "                 \"POINT(-70.66 -33.45)\",\n",
    "                 \"POINT(-74.08 4.60)\",\n",
    "                 \"POINT(-66.86 10.48)\",\n",
    "        ],})\n",
    "gdf[\"geometry\"] = gpd.GeoSeries.from_wkt(gdf[\"geometry\"])\n",
    "gdf.set_geometry(\"geometry\")\n",
    "gdf.crs=\"EPSG:4326\"\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377d9b5-7ed0-49ee-aeaa-063175026e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# render GeoDataFrame on an interactive map \n",
    "gdf.explore(tiles=\"CartoDB positron\", marker_kwds={\"radius\":8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e2209-ca81-4f63-b448-5c8805d9694a",
   "metadata": {},
   "source": [
    "#### Convert from the native spatial type to common formats\n",
    "Oracle Spatial includes functions and methods to convert from the native spatial type to common formats, including conversion to the WKT format used in a GeoDataFrame. So creating a GeoDataFrame from Oracle Spatial results is straightforward. The conversion syntax of object methods is more compact than the equivalent SQL functions. For example the method `(geometry).get_wkt()` versus the function `sdo_util.to_wktgeometry(geometry)`. Run the following to see a basic example of format conversions of a hard-coded SDO_GEOMETRY to WKT and GeoJSON formats using object methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e8d98-a7e7-4f61-a43c-67433e07070b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert native geometry data type to common string formats\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "  WITH x AS (\n",
    "    SELECT sdo_geometry(2001,4326,sdo_point_type(-100.12, 22.34,null),null,null) \n",
    "           as geometry\n",
    "    FROM dual)\n",
    "  SELECT geometry, \n",
    "         (geometry).get_wkt(), \n",
    "         (geometry).get_geojson()\n",
    "  FROM x\n",
    "  \"\"\")\n",
    "for row in cursor.fetchone():\n",
    "   print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf3d6f-2fe7-411b-9a52-cf3a0cd49196",
   "metadata": {},
   "source": [
    "#### Retrieve geometries using the function lonlat_to_proj_geom( )\n",
    "In previous steps you configured the LOCATIONS table with a function-based spatial index. The function is lonlat_to_proj_geom( ) and converts longitude, latitude into a SDO_GEOMETRY in the World Mercator coordinate system for compatibility with libraries used in a later lab. Run the following cell to retrieve geometries using that function as WKT format and preivew the data. Then, retrieve geometries using that function and create a GeoDataFrame. Finally, visualize the GeoDataFrame and mouse over locations to see their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e9355-ef10-4929-a0c4-97a54c617065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert geometries in locations table to WKT format\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "  SELECT lon, lat, (lonlat_to_proj_geom(lon,lat)).get_wkt()\n",
    "  FROM locations\n",
    "  \"\"\")\n",
    "for row in cursor.fetchmany(10):\n",
    "   print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d67c1-e866-4103-8ed7-112505990b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GeoDataFrame from the locations table\n",
    "cursor.execute(\"\"\"\n",
    " SELECT location_id, owner, (lonlat_to_proj_geom(lon,lat)).get_wkt()\n",
    " FROM locations\n",
    " \"\"\")\n",
    "gdf = gpd.GeoDataFrame(cursor.fetchall(), columns = ['location_id', 'owner', 'geometry'])\n",
    "gdf['geometry'] = shapely.from_wkt(gdf['geometry'])\n",
    "gdf.crs=\"EPSG:3857\"\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606317cd-40b8-4538-b0a5-c90104755c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# render the GeoDataFrame on a map\n",
    "gdf.explore(tiles=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb38d54-a4e3-45b3-8168-3a248ebbfc14",
   "metadata": {},
   "source": [
    "### Explore Transactions Data\n",
    "\n",
    "Run the following to create a GeoDataFrame from a query joining TRANSACTIONS to LOCATIONS. Then, visualize the GeoDataFrame. Mouse over an item to see transaction attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca239a38-7f3c-443a-aa68-6179cdbb55d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a geoDataFrame from a join of transactions and locations\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    " SELECT a.cust_id, a.trans_id, a.trans_epoch_date, \n",
    "  (lonlat_to_proj_geom(b.lon,b.lat)).get_wkt() \n",
    " FROM transactions a, locations b\n",
    " WHERE a.location_id=b.location_id\n",
    " \"\"\")\n",
    "gdf = gpd.GeoDataFrame(cursor.fetchall(), columns = ['cust_id', 'trans_id', 'trans_epoch_date', 'geometry'])\n",
    "gdf['geometry'] = shapely.from_wkt(gdf['geometry'])\n",
    "gdf.crs=\"EPSG:3857\"\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc9370-0c46-4a54-8549-d067df99a057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# render the GeoDataFrame on a map\n",
    "gdf.explore(tiles=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb1cfa-ebf2-4358-96ec-d9d38188bf68",
   "metadata": {},
   "source": [
    "### Experiment with Spatial Aggregation\n",
    "To calculate the distance of transactions from a spatiotemporal cluster, it is convenient to represent the cluster as a single geometry. This is a use case for spatial aggregation, where a set of geometries is represented by a single aggregate. Oracle Spatial provides a package of spatial aggregate functions for just this purpose. This task is meant to familiarize you with spatial aggregation.\n",
    "\n",
    "#### Create a GeoDataFrame of items from the LOCATIONS table\n",
    "Run the following cell to create a GeoDataFrame of items from the LOCATIONS table locations within 10 miles of a longitude/latitude coordinate in Austin, TX (-97.7431, 30.2672)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327ae90-57f7-467f-85aa-68361b5da0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GeoDataFrame of locations near a coordinate\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    " SELECT (lonlat_to_proj_geom(lon,lat)).get_wkt() as geometry\n",
    " FROM locations\n",
    " WHERE sdo_within_distance(\n",
    "           lonlat_to_proj_geom(lon,lat),\n",
    "           lonlat_to_proj_geom(-97.7431,30.2672),\n",
    "           'distance=10 unit=MILE') = 'TRUE'\n",
    "       \"\"\")\n",
    "gdfPoints = gpd.GeoDataFrame(cursor.fetchall(), columns = ['geometry'])\n",
    "gdfPoints['geometry'] = shapely.from_wkt(gdfPoints['geometry'])\n",
    "gdfPoints.crs = \"EPSG:3857\"\n",
    "gdfPoints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b163c-55be-46f1-a81b-7f80bd6acde2",
   "metadata": {},
   "source": [
    "#### Create a GeoDataFrame in the center of the previously selected locations\n",
    "Create a GeoDataFrame containing the location in the center of the previously selected locations. This location is referred to as an \"aggregate centroid\", hence the GeoDataFrame is named gdfAggCent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890105e-6590-4f08-949b-b3b86fa71e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GeoDataFrame of the aggregate centroid\n",
    "cursor.execute(\"\"\"\n",
    " SELECT SDO_AGGR_CENTROID(\n",
    "          SDOAGGRTYPE(lonlat_to_proj_geom(lon,lat), 0.005)).get_wkt() as geometry\n",
    " FROM locations\n",
    " WHERE sdo_within_distance(\n",
    "           lonlat_to_proj_geom(lon,lat),\n",
    "           lonlat_to_proj_geom(-97.7431,30.2672),\n",
    "           'distance=10 unit=MILE') = 'TRUE'\n",
    "       \"\"\")\n",
    "gdfAggCent = gpd.GeoDataFrame(cursor.fetchall(), columns = ['geometry'])\n",
    "gdfAggCent['geometry'] = shapely.from_wkt(gdfAggCent['geometry'])\n",
    "gdfAggCent.crs = \"EPSG:3857\"\n",
    "gdfAggCent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360078b7-dd03-4442-beb5-5744fcd5f4d9",
   "metadata": {},
   "source": [
    "#### Create a GeoDataFrame containing the shape that bounds the locations near the coordinate in Austin, TX\n",
    "Create a GeoDataFrame containing the shape that bounds the locations near the coordinate in Austin, TX. This is referred to as a \"aggregate convex hull\", hence the GeoDataFrame is named gdfAggHull. There are several other spatial aggregate functions that follow the same pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08977e-b78a-4e6f-995b-2bf76c308f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GeoDataFrame of the bounding area\n",
    "cursor.execute(\"\"\"\n",
    " SELECT SDO_AGGR_CONVEXHULL(\n",
    "          SDOAGGRTYPE(lonlat_to_proj_geom(lon,lat), 0.005)).get_wkt() as geometry\n",
    " FROM locations\n",
    " WHERE sdo_within_distance(\n",
    "           lonlat_to_proj_geom(lon,lat),\n",
    "           lonlat_to_proj_geom(-97.7431,30.2672),\n",
    "           'distance=10 unit=MILE') = 'TRUE'\n",
    "       \"\"\")\n",
    "gdfAggHull = gpd.GeoDataFrame(cursor.fetchall(), columns = ['geometry'])\n",
    "gdfAggHull['geometry'] = shapely.from_wkt(gdfAggHull['geometry'])\n",
    "gdfAggHull.crs = \"EPSG:3857\"\n",
    "gdfAggHull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee4451-e712-4066-83da-cc149e8d0b6e",
   "metadata": {},
   "source": [
    "#### Visualize the points and the two spatial aggregates you've created\n",
    "Visualize the points and the two spatial aggregates you've created. The original locations are shown in blue, and the aggregate centroid and aggregate convex hull are shown in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9732e-71a9-405c-a0b0-8d38a3fb6fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the original locations and aggregates\n",
    "m = gdfPoints.explore(tiles=\"CartoDB positron\",\n",
    "                       style_kwds={\"color\":\"blue\",\"fillColor\":\"blue\"})\n",
    "m = gdfAggHull.explore(m=m,\n",
    "                       style_kwds={\"color\":\"red\",\"fillOpacity\":\"0\"} )\n",
    "m = gdfAggCent.explore(m=m,\n",
    "                       marker_kwds={\"radius\":\"8\"},\n",
    "                      style_kwds={\"color\":\"red\",\"fillColor\":\"red\",\"fillOpacity\":\".7\"} )\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d7555-ffef-4064-9d8b-efb30e61d433",
   "metadata": {},
   "source": [
    "### Prep for Cluster Detection\n",
    "To start import libraries needed for detecting spatiotemporal clusters. The main library is st_dbscan. Also, the pandas and numpy libraries are required for configuration of the input to st_dbscan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349e25f-625e-4edf-b9d8-7cb544f30040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from st_dbscan import ST_DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68246d74-69ef-4607-8380-4aa89ad9c20f",
   "metadata": {},
   "source": [
    "#### Prep for Spatiotemportal Cluster detection\n",
    "Then, let's run through a simple example of detecting spatiotemporal clusters. Run the following to create a GeoDataFrame with some locations each having epoch time and an ID. The ST_DBSCAN library requires that coordinates be in the same unit as distance measurement. Therefore, we will then convert the coordinate system from longitude/latitude to projected x/y coordinates based on meters. The input to ST_DBSCAN is a Numpy array, so  convert the GeoDataFrame to a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a872901-a157-41a4-a2c1-f66e71c42f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GeoDataFrame including geometry and epoch date\n",
    "gdf = gpd.GeoDataFrame({\n",
    "    \"id\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    \"epoch_date\": [1704096000, 1687881600, 1687968000, 1688054400, 1688140800, \\\n",
    "                   1688227200, 1672656000, 1672742400, 1672828800,  1016730016, \\\n",
    "                   1673001600, 1673001600, 1672915200, 673001600, 1688054400],\n",
    "    \"geometry\": [\"POINT(-115.2368 36.2650)\",\n",
    "                \"POINT(-115.1356 36.1823)\",\n",
    "                \"POINT(-115.1492 36.1779)\",\n",
    "                \"POINT(-115.1385 36.1910)\",\n",
    "                \"POINT(-115.1256 36.1804)\",\n",
    "                \"POINT(-115.1329 36.1735)\",\n",
    "                \"POINT(-115.1711 36.1212)\",\n",
    "                \"POINT(-115.1656 36.1228)\",\n",
    "                \"POINT(-115.1782 36.1221)\",\n",
    "                \"POINT(-115.1695 36.1253)\",\n",
    "                \"POINT(-115.1790 36.1254)\",\n",
    "                \"POINT(-115.1388 36.1858)\",\n",
    "                \"POINT(-115.1669 36.1176)\",\n",
    "                \"POINT(-115.1755 36.1199)\",\n",
    "                \"POINT(-115.1297 36.1900)\",\n",
    "    ],})\n",
    "# convert to Shapely geometries\n",
    "gdf['geometry'] = shapely.from_wkt(gdf['geometry'])\n",
    "# assign longitude/latitude coordinate system\n",
    "gdf = gdf.set_crs(4326)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a3a72-3e39-4001-ae2d-7c789e06ce80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to projected x/y coordinates as required for st_dbscan\n",
    "gdf = gdf.to_crs(3857)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba15e32-d5af-4cd7-b1c7-294dc7e07295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "df = pd.DataFrame(data={'time': gdf.epoch_date, 'x': gdf.geometry.x, 'y': gdf.geometry.y, 'id':  gdf.id})\n",
    "data = df.values\n",
    "# Convert to numpy array\n",
    "data = np.int_(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f217d-bbf3-4406-baba-9f1c5a18ef01",
   "metadata": {},
   "source": [
    "#### Detect spatiotemporal clusters\n",
    "ST_DBSCAN is a variation of the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm that is extended to work with spatial data. The parameters are the thresholds for clusters; eps1 is the distance threshold in the units of the coordinate system (meters), eps2 is the time threshold in seconds, and min-samples is the threshold for minimum of items. Run the following to detect clusters where the thresholds are 5 or more items within 5KM and roughly 1 month. The result is an integer label for each input item. Each label >=0 represents a cluster. The label -1 indicates the item is not part of a cluster. Run the following cells to detect spatiotemporal clusrters, review the distinct set of resulting labels, add the integer label to the GeoDataFrame, and finally visualize the clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f4dc6-7af8-43a4-8183-4d077a8ddacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detect clusters \n",
    "st_cluster = ST_DBSCAN(eps1 = 5000, eps2 = 3000000, min_samples = 5)\n",
    "st_cluster.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d0c10-12e6-4d70-a0bd-98e278f17def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list the distinct cluster labels\n",
    "np.unique(st_cluster.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff716f-4217-42ac-9c7a-d37777044321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add cluster label to GeoDataFrame\n",
    "df = pd.DataFrame(data={'id': df.id, 'label': st_cluster.labels})\n",
    "label_mapping_dict = dict(zip(df[\"id\"], df[\"label\"]))\n",
    "gdf[\"label\"] = gdf[\"id\"].map(label_mapping_dict)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9d5a9-ad8f-4f34-873b-0deadb20a71c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize clusters\n",
    "gdf.explore(column=\"label\", categorical=\"True\", tiles=\"CartoDB positron\", \\\n",
    "            cmap=['sienna','blue','limegreen'], marker_kwds={\"radius\":4}, \\\n",
    "            style_kwds={\"fillOpacity\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5a310-7068-4aa8-8869-c3ea84b0d29c",
   "metadata": {},
   "source": [
    "#### Create table for labels\n",
    "The result of cluster detection is a \"label\" for every data item indicating if the item is part of a cluster, and if so which cluster. You will perform cluster analysis and save the results to the database for further analysis. Run the following to create a database table that will store cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811fb19-1f3e-4788-9e22-76e13512c75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create table to store cluster detection results (labelled transactions)\n",
    "cursor.execute(\"CREATE TABLE transaction_labels (trans_id integer, label integer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dba61e-a9b6-41b6-9ee2-a63059f1d538",
   "metadata": {},
   "source": [
    "#### Prep for spatiotemporal cluster detection for customers\n",
    "Run the following to set a variable for the customer id for analysis, create a GeoDataframe of customer's transactions, and convert to Numpy array for cluster detection. Notice the binding syntax in the WHERE clause (cust_id=:cust) supported by the python-oracledb driver. Then, convert your GeoDataFrame to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186e1cc-5dd7-4d3b-9122-9cd44ceb6120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set customer id for analysis\n",
    "cust=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be190daf-7de7-4a4a-a8e8-b6b64426cb51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GeoDataFrame of customer's transactions\n",
    "cursor.execute(\"\"\"\n",
    " SELECT a.cust_id,  a.trans_id, a.trans_epoch_date,\n",
    "       (lonlat_to_proj_geom(b.lon,b.lat)).get_wkt()\n",
    " FROM transactions a, locations b\n",
    " WHERE a.location_id=b.location_id\n",
    " AND cust_id=:cust\"\"\", cust=cust)\n",
    "gdf = gpd.GeoDataFrame(cursor.fetchall(), columns = ['cust_id', 'trans_id', 'epoch_date', 'geometry'])\n",
    "gdf['geometry'] = shapely.from_wkt(gdf['geometry'])\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f086882-8a2d-49ef-bed0-e0b2d6357cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first convert to pandas dataframe\n",
    "df = pd.DataFrame(data={'time': gdf.epoch_date, 'x': gdf.geometry.x, 'y': gdf.geometry.y, 'trans_id':  gdf.trans_id, 'cust_id':gdf.cust_id})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345f82c-7cd0-43be-90d1-cf4613c884f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# then convert to numpy array for st_dbscan\n",
    "data = df.values\n",
    "data = np.int_(data)\n",
    "data[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f46f0a-d23c-4e56-9332-f484700488e6",
   "metadata": {},
   "source": [
    "#### Detect spatiotemporal clusters\n",
    "\n",
    "You are now ready to detect spatiotemporal clusters for customer cust_id = 1. The operation accepts three threshold parameters: distance, time, and minimum number of items. Items with neighbors within the distance and time thresholds are considered part of a cluster, and there most be at least the minimum number of items to qualify as a cluster. Distance is in the units of the coordinate system, which in this case is meters. Time is in seconds. Run the following to detect clusters where the thresholds are 5 or more items within 5KM and roughly 1 month. The result is an integer label for each input item. Each label >=0 represents a cluster. The label -1 indicates the item is not part of a cluster. Review the distinct set of resulting labels. Then, add the cluster labels to transactions and print the first several rows. Each transaction is labelled with either -1 (meaning not part of a cluster) or an integer >=0 (meaning the cluster the item belongs to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb99135-ffa9-4dae-9b89-54da5ac67d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform cluster detection\n",
    "st_cluster = ST_DBSCAN(eps1 = 5000, eps2 = 3000000, min_samples = 5)\n",
    "st_cluster.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449deae4-6375-4348-bb2b-18a784f58363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list the distinct cluster labels\n",
    "np.unique(st_cluster.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c97aa-87c7-4e9e-81e0-2ede01799d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the cluster labels to the DataFrame as a column \n",
    "df = pd.DataFrame(data={'trans_id': df.trans_id, 'label': st_cluster.labels})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99a7ca5-04d7-498c-bf8a-7227a6c202eb",
   "metadata": {},
   "source": [
    "#### Visualize spatiotemporal clusters for customers\n",
    "Detecting anomalies will require database queries involving the cluster labels. So run the following to insert the the current customer's labelled transactions to the TRANSACTION_LABELS table created in previous steps. Then, retrieve the current customer's transactions with their cluster labels. Then visualize the current customer's labelled transactions. In this case you include the parameter for color coding the items based on cluster label. You may also mouse over an item to see its attributes including the cluster label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbae725-013c-4f09-ba06-b28bc072cf01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insert the labeled transactions to transaction_labels table\n",
    "cursor.executemany(\"\"\"\n",
    " INSERT INTO transaction_labels\n",
    " VALUES (:1, :2)\"\"\",\n",
    " list(df[['trans_id','label']].itertuples(index=False, name=None)))\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58468894-bb5a-4fab-9b29-04e732f4f492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labelled transactions for customer\n",
    "cursor.execute(\"\"\"\n",
    " SELECT a.cust_id, a.location_id, a.trans_id, a.trans_epoch_date,\n",
    "        (lonlat_to_proj_geom(b.lon,b.lat)).get_wkt(), c.label\n",
    " FROM transactions a, locations b, transaction_labels c\n",
    " WHERE a.location_id=b.location_id\n",
    " AND a.trans_id=c.trans_id\n",
    " \"\"\")\n",
    "gdf = gpd.GeoDataFrame(cursor.fetchall(), columns = ['cust_id', 'location_id', 'trans_id', 'trans_epoch_date', 'geometry','label'])\n",
    "gdf['geometry'] = shapely.from_wkt(gdf['geometry'])\n",
    "gdf = gdf.set_crs(3857)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77486cff-70e4-4881-a9a8-7dd6588ab91b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize labelled transactions for customer\n",
    "gdf.explore(column=\"label\", categorical=\"True\", tiles=\"CartoDB positron\", \\\n",
    "            marker_kwds={\"radius\":4}, style_kwds={\"fillOpacity\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d4dae-51d2-4de8-833a-9be72d4e9459",
   "metadata": {},
   "source": [
    "### Detect Anomolies\n",
    "\n",
    "Run the following to create aggregate centroids for the current customer's spatiotemporal clusters with attributes for cluster label, time range, and number of transactions in the cluster. Observe the first customer has only 1 cluster (label = 0). Then, visualize the spatiotemporal cluster centroid and mouse over the centroid to see its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268500a6-8726-48bc-abae-aa99739752eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create GeoDataFrame with cluster centroids for customer\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    " SELECT label, min(trans_epoch_date) as min_time, max(trans_epoch_date) as max_time,\n",
    "         SDO_AGGR_CENTROID(\n",
    "          SDOAGGRTYPE(lonlat_to_proj_geom(b.lon,b.lat), 0.005)).get_wkt() as geometry,\n",
    "         count(*) as trans_count\n",
    " FROM transactions a, locations b, transaction_labels c\n",
    " WHERE a.location_id=b.location_id\n",
    " AND a.trans_id=c.trans_id\n",
    " AND c.label != -1\n",
    " GROUP BY label\n",
    "       \"\"\")\n",
    "gdf = gpd.GeoDataFrame(cursor.fetchall(), columns = ['label','min_time','max_time','geometry','trans_count'])\n",
    "gdf['geometry'] = shapely.from_wkt(gdf['geometry'])\n",
    "gdf = gdf.set_crs(3857)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7907e-7701-4b30-a9ee-368b58c21a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize cluster centroids for customer\n",
    "gdf.explore(tiles=\"CartoDB positron\", marker_kwds={\"radius\":4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d9a83-d93d-4b6b-b822-dc4c2e13628c",
   "metadata": {},
   "source": [
    "#### Identify current customer transactions within the time/location range\n",
    "To identify current customer transactions within the time range of cluster(s) and located at a distance greater than a threshold, you will run a query using WITH … AS … SELECT .. WHERE… syntax as follows. \n",
    "```\n",
    "WITH\n",
    "    x as ( [transactions] ),\n",
    "    y as ( [spatiotemporal cluster aggregate centroids] )\n",
    "SELECT [transaction, cluster label, distance from cluster aggregate centroid, ...]\n",
    "FROM x, y\n",
    "WHERE [transaction time within cluster time frame]\n",
    "AND [distance from cluster > threshold]\n",
    "\n",
    "```\n",
    "  \n",
    "Run the following to return suspicious transactions along with the associated cluster label and distance from the cluster. Then, visualize the spatiotemporal cluster(s) as blue markers and associated suspicious outlier(s) as red markers. Hover over the suspicious transaction(s) to see their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246cc449-0274-4b20-807d-6733059305eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# identify anomalies (suspicious transactions) for customer\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "WITH\n",
    "   x as (\n",
    "       SELECT a.cust_id, a.location_id, a.trans_id, a.trans_epoch_date,\n",
    "              lonlat_to_proj_geom(b.lon,b.lat) as proj_geom, c.label\n",
    "       FROM transactions a, locations b, transaction_labels c\n",
    "       WHERE a.location_id=b.location_id\n",
    "       AND a.trans_id=c.trans_id ),\n",
    "   y as (\n",
    "       SELECT label, min(trans_epoch_date) as min_time, max(trans_epoch_date) as max_time,\n",
    "              SDO_AGGR_CENTROID(\n",
    "                  SDOAGGRTYPE(lonlat_to_proj_geom(b.lon,b.lat), 0.005)) as proj_geom,\n",
    "              count(*) as trans_count\n",
    "       FROM transactions a, locations b, transaction_labels c\n",
    "       WHERE a.location_id=b.location_id\n",
    "       AND a.trans_id=c.trans_id\n",
    "       AND c.label != -1\n",
    "       GROUP BY label)\n",
    " SELECT x.cust_id, x.trans_epoch_date, (x.proj_geom).get_wkt(), x.trans_id, x.label, y.label,\n",
    "        round(sdo_geom.sdo_distance(x.proj_geom, y.proj_geom, 0.05, 'unit=KM'))\n",
    " FROM x, y\n",
    " WHERE x.trans_epoch_date between y.min_time and y.max_time\n",
    " AND x.label!=y.label\n",
    " AND x.label=-1\n",
    " AND sdo_within_distance(x.proj_geom, y.proj_geom, 'distance=500 unit=KM') = 'FALSE'\n",
    "       \"\"\")\n",
    "gdfAnomaly = gpd.GeoDataFrame(cursor.fetchall(), columns = ['cust_id','trans_epoch_date','geometry', 'trans_id','label','outlier_to_label','distance'])\n",
    "gdfAnomaly['geometry'] = shapely.from_wkt(gdfAnomaly['geometry'])\n",
    "gdfAnomaly = gdfAnomaly.set_crs(3857)\n",
    "gdfAnomaly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66d64b-9fa5-4edb-add2-9ab24afff43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize suspicious transactions for customer\n",
    "m = gdf.explore(tiles=\"CartoDB positron\", marker_type='circle_marker',marker_kwds={\"radius\":\"5\"},\n",
    "                style_kwds={\"color\":\"blue\",\"fillColor\":\"blue\", \"fillOpacity\":\"1\"})\n",
    "m = gdfAnomaly.explore(m=m, marker_type='circle_marker', marker_kwds={\"radius\":\"5\"},\n",
    "                       style_kwds={\"color\":\"red\",\"fillColor\":\"red\", \"fillOpacity\":\"1\"} )\n",
    "m.fit_bounds(m.get_bounds())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664d22d-3958-45d3-9f55-5ab5db1e318d",
   "metadata": {},
   "source": [
    "#### Repeat the process for other customers\n",
    "To repeat the process for other customer's transactions you could scroll up to the cell where customer ID is set, update to a different customer ID, and rerun the subsequent cells. However it is more convenient to use a script that runs all of the steps.  \n",
    "\n",
    "Follow Lab 7, Task 4, Step 5-6 of your Workshop to load a script to run all the steps for anomaly detection.\n",
    "  \n",
    "The functions in the script will reproduce the previous steps starting from Task 3 after emptying the TRANSACTION_LABELS table as a new set of labels.\n",
    "- create_connection() establishes a database connection\n",
    "- get_cluster_centroids( ) detects spatiotemporal transaction clusters for a customer\n",
    "- get_anomalies( ) identifies suspicious transactions based on overlapping time and distance beyond threshold from clusters\n",
    "- get_map( ) returns a map of clusters and associated suspicious transactions\n",
    "  \n",
    "Run through the following steps to import the script, analyze othercustomer's transactions using functions in the script, and detect suspicious transactions. Repeat these steps with other customer IDs (1-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53960bd8-402a-418f-9642-7fdfb1ccfac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from anomaly_detection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfc6f5-1729-4fe3-a285-1c354a63be90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the customer id for analysis\n",
    "cust = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716686a-987e-4c40-9575-c6466a2045bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run functions to detect anomalies (suspicious transactions)\n",
    "create_connection()\n",
    "gdf = get_cluster_centroids(cust)\n",
    "gdfAnomaly = get_anomalies(cust)\n",
    "m = get_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f01ac-f5f4-4d16-9eca-cb8e29019d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list the spatiotemporal transaction clusters for customer\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758dde48-3957-4c1d-aece-78d5da5c5f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list the anomalies (suspicious transactions) for customer\n",
    "gdfAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df0f01-0f60-44c7-a236-02eb1fafccab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the anomalies (suspicious transactions) for customer\n",
    "m.fit_bounds(m.get_bounds())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731206a1-1af3-4906-b44f-5af6426c03ea",
   "metadata": {},
   "source": [
    "To detect suspicious for other customers, rerun the last 5 cells starting with a different value for the cust variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b894cf4-ce3a-45f6-bd57-389631e75723",
   "metadata": {},
   "source": [
    "#### Cleanup (Optional)\n",
    "You may run the following to reset your Autonomous Database to pre-workshop state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e77e9-b0c7-4ad1-a46c-10465e55dafd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop all database artifacts created in this hands-on lab\n",
    "import oracledb\n",
    "my_pwd = open('./my-pwd.txt','r').readline().strip()\n",
    "my_dsn = open('./my-dsn.txt','r').readline().strip()\n",
    "connection = oracledb.connect(user=\"admin\", password=my_pwd, dsn=my_dsn)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"drop table transactions\")\n",
    "cursor.execute(\"drop table locations\")\n",
    "cursor.execute(\"drop table transaction_labels\")\n",
    "cursor.execute(\"drop function lonlat_to_proj_geom\")\n",
    "cursor.execute(\"delete from user_sdo_geom_metadata\")\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf6ee3",
   "metadata": {},
   "source": [
    "We hope this workshop has been informative and that you further explore the spatial features of Oracle Database and their use in machine learning and AI workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
